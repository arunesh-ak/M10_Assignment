{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc19688",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b99aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/b4/f9/e9ac5e4c5d84b07c7d117d67b2c84be221bcb9e62ff31fd0a1bbc06099c0/selenium-4.19.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.19.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/17/c9/f86f89f14d52f9f2f652ce24cb2f60141a51d087db1563f3fba94ba07346/trio-0.25.0-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.25.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Collecting typing_extensions>=4.9.0 (from selenium)\n",
      "  Obtaining dependency information for typing_extensions>=4.9.0 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for attrs>=23.2.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sniffio>=1.3.0 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for h11<1,>=0.9.0 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.19.0-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/10.5 MB 31.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.7/10.5 MB 34.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.2/10.5 MB 41.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.4/10.5 MB 42.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.5 MB 44.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 40.9 MB/s eta 0:00:00\n",
      "Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
      "   ---------------------------------------- 0.0/467.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 467.2/467.2 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Installing collected packages: typing_extensions, sniffio, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.1.0\n",
      "    Uninstalling attrs-22.1.0:\n",
      "      Successfully uninstalled attrs-22.1.0\n",
      "Successfully installed attrs-23.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.19.0 sniffio-1.3.1 trio-0.25.0 trio-websocket-0.11.1 typing_extensions-4.11.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee4cf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_managerNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for webdriver_manager from https://files.pythonhosted.org/packages/b1/51/b5c11cf739ac4eecde611794a0ec9df420d0239d51e73bc19eb44f02b48b/webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raiar\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2023.7.22)\n",
      "Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver_manager\n",
      "Successfully installed webdriver_manager-4.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b58323",
   "metadata": {},
   "source": [
    "## Module 10 Assignment - Scraping a Website\n",
    "* Author: brandon chiazza\n",
    "* version 2.0\n",
    "\n",
    "We will be creating a web scraper to parse a table from the Charities Bureau Website. From the website: “All \n",
    "charitable organizations operating in New York State are required by law to register and file annual financial reports \n",
    "with the Attorney General's Office. This includes any organization that conducts charitable activities, holds property \n",
    "that is used for charitable purposes, or solicits financial or other contributions.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a378dd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>NY Reg #</th>\n",
       "      <th>EIN</th>\n",
       "      <th>Registrant Type</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Forever Captain Poodaman\" The Ahmad Butler Fo...</td>\n",
       "      <td>48-07-16</td>\n",
       "      <td>843800926</td>\n",
       "      <td>NFP</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Incredibly Blessed\" Inc</td>\n",
       "      <td>49-54-61</td>\n",
       "      <td>842071758</td>\n",
       "      <td>NFP</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"R\" S.U.C.C.E.S.S. Foundation Inc.</td>\n",
       "      <td>49-06-59</td>\n",
       "      <td>874012670</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Studio 5404\" Inc.</td>\n",
       "      <td>44-39-58</td>\n",
       "      <td>463180470</td>\n",
       "      <td>NFP</td>\n",
       "      <td>MASSAPAQUA</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"THEY ARE HAITIAN\" FUND, INC.</td>\n",
       "      <td>20-63-46</td>\n",
       "      <td>300170128</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HUDSON</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Y\" Dive, Inc.</td>\n",
       "      <td>48-45-01</td>\n",
       "      <td>854252095</td>\n",
       "      <td>NFP</td>\n",
       "      <td>SAINT ALBANS</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(ASMA) American Syrian Multicultural Associati...</td>\n",
       "      <td>42-84-63</td>\n",
       "      <td>273130182</td>\n",
       "      <td>NFP</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#FeedHamburg</td>\n",
       "      <td>48-37-35</td>\n",
       "      <td>854150318</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HAMBURG</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#HicksStrong Inc.</td>\n",
       "      <td>48-10-48</td>\n",
       "      <td>842612081</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CLIFTON PARK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#WalkAway Foundation</td>\n",
       "      <td>47-15-80</td>\n",
       "      <td>832820906</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CARLSBAD</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>04/11 10:17 PM test</td>\n",
       "      <td>47-13-95</td>\n",
       "      <td>206256427</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/20/21 Action Fund</td>\n",
       "      <td>46-99-13</td>\n",
       "      <td>832210730</td>\n",
       "      <td>NFP</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10/40 Connections, Inc.</td>\n",
       "      <td>45-70-15</td>\n",
       "      <td>621825230</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HIXSON</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000 Feet Project, Inc</td>\n",
       "      <td>45-00-14</td>\n",
       "      <td>473820859</td>\n",
       "      <td>NFP</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000 Islands Hose Haulers</td>\n",
       "      <td>45-38-38</td>\n",
       "      <td>454570241</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CARTHAGE</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Organization Name  NY Reg #        EIN  \\\n",
       "0   \"Forever Captain Poodaman\" The Ahmad Butler Fo...  48-07-16  843800926   \n",
       "1                            \"Incredibly Blessed\" Inc  49-54-61  842071758   \n",
       "2                  \"R\" S.U.C.C.E.S.S. Foundation Inc.  49-06-59  874012670   \n",
       "3                                  \"Studio 5404\" Inc.  44-39-58  463180470   \n",
       "4                       \"THEY ARE HAITIAN\" FUND, INC.  20-63-46  300170128   \n",
       "5                                      \"Y\" Dive, Inc.  48-45-01  854252095   \n",
       "6   (ASMA) American Syrian Multicultural Associati...  42-84-63  273130182   \n",
       "7                                        #FeedHamburg  48-37-35  854150318   \n",
       "8                                   #HicksStrong Inc.  48-10-48  842612081   \n",
       "9                                #WalkAway Foundation  47-15-80  832820906   \n",
       "10                                04/11 10:17 PM test  47-13-95  206256427   \n",
       "11                                1/20/21 Action Fund  46-99-13  832210730   \n",
       "12                            10/40 Connections, Inc.  45-70-15  621825230   \n",
       "13                             1000 Feet Project, Inc  45-00-14  473820859   \n",
       "14                          1000 Islands Hose Haulers  45-38-38  454570241   \n",
       "\n",
       "   Registrant Type           City State  \n",
       "0              NFP   PHILADELPHIA    PA  \n",
       "1              NFP  STATEN ISLAND    NY  \n",
       "2              NFP      ROCHESTER    NY  \n",
       "3              NFP     MASSAPAQUA    NY  \n",
       "4              NFP         HUDSON    NY  \n",
       "5              NFP   SAINT ALBANS    NY  \n",
       "6              NFP       BROOKLYN    NY  \n",
       "7              NFP        HAMBURG    NY  \n",
       "8              NFP   CLIFTON PARK    NY  \n",
       "9              NFP       CARLSBAD    CA  \n",
       "10             NFP         ALBANY    NY  \n",
       "11             NFP  SAN FRANCISCO    CA  \n",
       "12             NFP         HIXSON    TN  \n",
       "13             NFP       NEW YORK    NY  \n",
       "14             NFP       CARTHAGE    NY  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Load modules\n",
    "#!pip install webdriver-manager\n",
    "#!pip install awscli\n",
    "import awscli\n",
    "import boto3\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "####SCRAPE THE WEBSITE######\n",
    "###call the webdriver\n",
    "s=Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=s)\n",
    "\n",
    "#enter the url path that needs to be accessed by webdriver\n",
    "browser.get('https://www.charitiesnys.com/RegistrySearch/search_charities.jsp')\n",
    "\n",
    "#identify xpath of location to select element\n",
    "inputElement = browser.find_element(By.XPATH,'//*[@id=\"header\"]/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[2]/td[2]/input[1]') #identifies the location of the EIN element\n",
    "inputElement.send_keys('0') #sends the \"0\" as the search value for EIN \n",
    "inputElement1 = browser.find_element(By.XPATH,'//*[@id=\"header\"]/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[10]/td/input[1]').click() #instatiates the click of the search\n",
    "sleep(4) #allow for the page to load by adding a sleep element\n",
    "#identify the table to scrape\n",
    "table = browser.find_element(By.CSS_SELECTOR,'table.Bordered')\n",
    "sleep(1)\n",
    "#####CREATE DATE FRAME#####\n",
    "#create empty dataframe\n",
    "df =[]\n",
    "\n",
    "#loop through dataframe to export table\n",
    "\n",
    "\n",
    "#page = browser.find_element(By.XPATH,'/html/body/div[2]/div/table/tbody/tr/td[3]/div/div/span[2]/a[9]')\n",
    "\n",
    "#loop through dataframe to export table\n",
    "for row in table.find_elements(By.CSS_SELECTOR,'tr'):\n",
    "    if row.find_elements(By.XPATH, './parent::thead'):\n",
    "        continue  # Skip rows within the <thead> section\n",
    "    cols = df.append([cell.text for cell in row.find_elements(By.CSS_SELECTOR,'td')])\n",
    "\n",
    "#update dataframe with header \n",
    "df = pd.DataFrame(df, columns = [\"Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State\"])\n",
    "display(df) #let's have a look at the data before creating the CSV file and loading it into s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81db30e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull uploaded file to location:s3://m10assign/charities_bureau_scrape_20240414173637.csv\n"
     ]
    }
   ],
   "source": [
    "###LOAD THE FILE INTO S3####\n",
    "# prepare csv file name   \n",
    "pathname = 's3://m10assign/' #specify location of s3:/{my-bucket}/\n",
    "filename= 'charities_bureau_scrape_' #name of your group\n",
    "datetime = time.strftime(\"%Y%m%d%H%M%S\") #timestamp\n",
    "filenames3 = \"%s%s%s.csv\"%(pathname,filename,datetime) #name of the filepath and csv file\n",
    "\n",
    "#load file into s3. Pandas actually leverages boto to connect to s3 and can push the file directly into an s3 bucket\n",
    "df.to_csv(filenames3, header=True) \n",
    "\n",
    "#print success message\n",
    "print(\"Successfull uploaded file to location:\"+str(filenames3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122bdc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic function to read and validate the data loaded into S3 bucket\n",
    "def print_bucket_contents(bucket):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(Bucket=bucket)\n",
    "\n",
    "    if 'Contents' in response:\n",
    "        print(\"Contents of the '{}' bucket:\".format(bucket))\n",
    "        for obj in response['Contents']:\n",
    "            print(obj['Key'])\n",
    "    else:\n",
    "        print(\"The bucket '{}' is empty.\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197f100",
   "metadata": {},
   "source": [
    "## Evidence that my file is updated in the my bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b277a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the 'm10assign' bucket:\n",
      "charities_bureau_scrape_20240414173601.csv\n",
      "charities_bureau_scrape_20240414173637.csv\n"
     ]
    }
   ],
   "source": [
    "print_bucket_contents('m10assign')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb7934",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://www.programiz.com/python-programming/working-csv-files\n",
    "* https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.create_bucket\n",
    "* https://realpython.com/python-boto3-aws-s3/\n",
    "* https://robertorocha.info/setting-up-a-selenium-web-scraper-on-aws-lambda-with-python/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b5508",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b944d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3860d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Added from all the pages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>NY Reg #</th>\n",
       "      <th>EIN</th>\n",
       "      <th>Registrant Type</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Forever Captain Poodaman\" The Ahmad Butler Fo...</td>\n",
       "      <td>48-07-16</td>\n",
       "      <td>843800926</td>\n",
       "      <td>NFP</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Incredibly Blessed\" Inc</td>\n",
       "      <td>49-54-61</td>\n",
       "      <td>842071758</td>\n",
       "      <td>NFP</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"R\" S.U.C.C.E.S.S. Foundation Inc.</td>\n",
       "      <td>49-06-59</td>\n",
       "      <td>874012670</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Studio 5404\" Inc.</td>\n",
       "      <td>44-39-58</td>\n",
       "      <td>463180470</td>\n",
       "      <td>NFP</td>\n",
       "      <td>MASSAPAQUA</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"THEY ARE HAITIAN\" FUND, INC.</td>\n",
       "      <td>20-63-46</td>\n",
       "      <td>300170128</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HUDSON</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>University of Virginia Health Foundtion</td>\n",
       "      <td>40-44-88</td>\n",
       "      <td>412097394</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CHARLOTTESVILLE</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Violin Player</td>\n",
       "      <td>41-40-19</td>\n",
       "      <td>270773158</td>\n",
       "      <td>NFP</td>\n",
       "      <td>LONDONDERRY</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>William A. Epps Community Center, Inc.</td>\n",
       "      <td>40-91-11</td>\n",
       "      <td>861074714</td>\n",
       "      <td>NFP</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>WORLD SOCIETY OF CZESTOCHOWA JEWS AND THEIR DE...</td>\n",
       "      <td>40-46-49</td>\n",
       "      <td>205101779</td>\n",
       "      <td>NFP</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Yum-O Organization, Inc.</td>\n",
       "      <td>40-50-07</td>\n",
       "      <td>208107545</td>\n",
       "      <td>NFP</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Organization Name  NY Reg #        EIN  \\\n",
       "0   \"Forever Captain Poodaman\" The Ahmad Butler Fo...  48-07-16  843800926   \n",
       "1                            \"Incredibly Blessed\" Inc  49-54-61  842071758   \n",
       "2                  \"R\" S.U.C.C.E.S.S. Foundation Inc.  49-06-59  874012670   \n",
       "3                                  \"Studio 5404\" Inc.  44-39-58  463180470   \n",
       "4                       \"THEY ARE HAITIAN\" FUND, INC.  20-63-46  300170128   \n",
       "..                                                ...       ...        ...   \n",
       "95            University of Virginia Health Foundtion  40-44-88  412097394   \n",
       "96                                      Violin Player  41-40-19  270773158   \n",
       "97             William A. Epps Community Center, Inc.  40-91-11  861074714   \n",
       "98  WORLD SOCIETY OF CZESTOCHOWA JEWS AND THEIR DE...  40-46-49  205101779   \n",
       "99                           Yum-O Organization, Inc.  40-50-07  208107545   \n",
       "\n",
       "   Registrant Type             City State  \n",
       "0              NFP     PHILADELPHIA    PA  \n",
       "1              NFP    STATEN ISLAND    NY  \n",
       "2              NFP        ROCHESTER    NY  \n",
       "3              NFP       MASSAPAQUA    NY  \n",
       "4              NFP           HUDSON    NY  \n",
       "..             ...              ...   ...  \n",
       "95             NFP  CHARLOTTESVILLE    VA  \n",
       "96             NFP      LONDONDERRY    NH  \n",
       "97             NFP    STATEN ISLAND    NY  \n",
       "98             NFP         NEW YORK    NY  \n",
       "99             NFP         NEW YORK    NY  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "####SCRAPE THE WEBSITE######\n",
    "###call the webdriver\n",
    "s=Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=s)\n",
    "\n",
    "#enter the url path that needs to be accessed by webdriver\n",
    "browser.get('https://www.charitiesnys.com/RegistrySearch/search_charities.jsp')\n",
    "\n",
    "#identify xpath of location to select element\n",
    "inputElement = browser.find_element(By.XPATH, \"/html/body/div/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[2]/td[2]/input[1]\")\n",
    "inputElement.send_keys('0')\n",
    "inputElement1 = browser.find_element(By.XPATH,\"/html/body/div/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[10]/td/input[1]\").click()\n",
    "\n",
    "df = []  # Empty list to store data from each page\n",
    "while True:\n",
    "    try:\n",
    "        element_next = browser.find_element(By.XPATH, '/html/body/div[2]/div/table/tbody/tr/td[3]/div/div/span[2]/a[text()=\"Next\"]')\n",
    "        sleep(1)\n",
    "        table = browser.find_element(By.CSS_SELECTOR,'table.Bordered')\n",
    "        sleep(1)\n",
    "        for row in table.find_elements(By.CSS_SELECTOR,'tr'):\n",
    "            if row.find_elements(By.XPATH, './parent::thead'):\n",
    "                continue  # Skip rows within the <thead> section\n",
    "            df.append([cell.text for cell in row.find_elements(By.CSS_SELECTOR,'td')])\n",
    "        element_next.click()\n",
    "        sleep(4)\n",
    "    except NoSuchElementException:\n",
    "        table = browser.find_element(By.CSS_SELECTOR,'table.Bordered')\n",
    "        sleep(1)\n",
    "        for row in table.find_elements(By.CSS_SELECTOR,'tr'):\n",
    "            if row.find_elements(By.XPATH, './parent::thead'):\n",
    "                continue  # Skip rows within the <thead> section\n",
    "            df.append([cell.text for cell in row.find_elements(By.CSS_SELECTOR,'td')])\n",
    "        # Handle the case where \"Next\" button is not found (reached last page)\n",
    "        print(\"Data Added from all the pages.\")\n",
    "        break\n",
    "#update dataframe with header \n",
    "df = pd.DataFrame(df, columns = [\"Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State\"])\n",
    "display(df) #let's have a look at the data before creating the CSV file and loading it into s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb786d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull uploaded file to location:s3://m10assign/charities_bureau_scrape_allpage_20240414180923.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###LOAD THE FILE INTO S3####\n",
    "# prepare csv file name   \n",
    "pathname = 's3://m10assign/' #specify location of s3:/{my-bucket}/\n",
    "filename= 'charities_bureau_scrape_allpage_' #name of your group\n",
    "datetime = time.strftime(\"%Y%m%d%H%M%S\") #timestamp\n",
    "filenames3 = \"%s%s%s.csv\"%(pathname,filename,datetime) #name of the filepath and csv file\n",
    "\n",
    "#load file into s3. Pandas actually leverages boto to connect to s3 and can push the file directly into an s3 bucket\n",
    "df.to_csv(filenames3, header=True) \n",
    "\n",
    "#print success message\n",
    "print(\"Successfull uploaded file to location:\"+str(filenames3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9b6b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the 'm10assign' bucket:\n",
      "charities_bureau_scrape_20240414173637.csv\n",
      "charities_bureau_scrape_allpage_20240414180923.csv\n"
     ]
    }
   ],
   "source": [
    "print_bucket_contents('m10assign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10387fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
